11. The Harm from Closed Source

A framework for evaluation that provides a great starting point was recent proposed by open source advocate and libertarian Eric S. Raymond.[78] Raymond's framework is not directly applicable for our purposes for several reasons. First, he does not take into account the technical ability of users, something appropriate for his audience that consists mainly of computer programmers, but not the audience of this book. Secondly, though Raymond does support using permissive licenses rather than copyleft licenses such as the GPL,[79] in this particular essay he is only proposing a framework for evaluating the harms of closed source against open source licensed software. All of our ideal licenses qualify as open source licenses, but some open source licenses use copyright to place restrictions on their users. Therefore our complete framework must go beyond the one proposed by Raymond's.

The different kinds of harm proposed by Raymond are very useful for our purposes because they all are reasons to support the least restrictive license possible instead of a closed source license. Raymond names the six kinds of harm that comes from closed source software - reliability harm, unhackability harm, agency harm, lock-in harm, amnesia harm and positive network effects.

Reliability harm comes from the idea that software bugs thrive on secrecy and thus when source code is released, more of them are found. Of course this is more of an empirical claim than a theoretical one. Most famously, a 2002 paper published by the now defunct Alexis de Tocqueville Institution claimed that "Open source GPL [General Public License] use by government agencies could easily become a national security concern. Government use of software in the public domain is exceptionally risky."[80] However, the claim shows a lack of understanding of how software security risks are exploited. As A. Boulanger explains in the IBM Systems Journal:

>Hiding the source code for a system does not provide any additional security. People searching for vulnerabilities do not require source code to discover software defects. For example, a common way to locate a software defect is to send a program unexpected and unusual data and then monitor how the system responds. If the system fails or behaves erratically as a result of the input, this might indicate a ﬂaw in the system that would warrant further investigation.

>With the prevalence of sophisticated software monitoring, debugging, and disassembly tools, much of the source code can be derived from the binary version of the executable program. Anyone interested in obtaining the source code would simply have to apply one of many widely available tools to the program. The output from these programs, while not perfect, would deliver sufﬁcient information to make it fairly easy to understand the internal working of the system.[81]

Evidence for the improved reliability of open source software is not just theoretical. There is plenty of empirical evidence to support the claim as well. A series of studies in 2003 by a company called Reasoning using their automated tools for assessing software reliability found that in measures of defects per line of code. To give some idea of the average defect rates, in their most recent 200 projects Reasoning found an average of .57 defects per thousand lines a code with one third of projects having a defect rate under 0.36 per thousand lines and one third having a rate greater than 0.71.

In one such study the examined 6 different implementations of the TCP/IP protocol which underlies the Internet.[82] The 5 proprietary version of the code had an average of .55 defects per thousand lines of code, very close to the benchmark average for a wider range of programs subjected to Reasoning analysis. Linux only had .10 defects per thousand lines of code, just 8 defects in over 82 thousand lines of code. The proprietary versions are not examples of brand new untested code either. 4 of the 5 had been in commercial use for over 10 years while the fifth was relatively new at only 3 years old. Of the 8 defects found, the Linux kernel networking mailing list told Reasoning that 1 of the bugs they found was real and that 4 were not errors at all, leaving 3 unconfirmed at the time the report was published. The confirmed bug had also already been found and fixed by Linux developers in the 2.4.20 release.

Another study by Reasoning of the GPL-licensed MySQL database software found similar results.[83] The reasoning analysis found just 21 defects in over 235 thousand lines of code for an error rate of only .09 defects per thousand lines of code. By comparison, the proprietary database software that Reasoning examined had an average of .58 defects per thousand lines of code, once again very close to their benchmark average.
It is also noteworthy that a third Reasoning study of a pre-release version of the Apache web server found a similar number of defects to proprietary software at that stage in the development process. This suggests that the open source development process finds and fixes more bugs faster, rather than starting from better code.[84]

There are also plenty more evidence and studies demonstrating the improved reliability of open source software over comparable proprietary versions that is focused on the metrics that have more meaning to users of the software than defects per line of code. Those discussions will be saved for the following chapters when the particular software is being discussed as a way to have a better gauge for the reliability harm of those specific software choices. For example, studies comparing operating system uptime between specific operating systems will be saved for the chapter on operating systems and comparisons of the number of days for which there is a known unpatched vulnerability in specific web browsers for the the chapter on web browsers.

This harm can be said to vary in response to the variables of the length of the code and the potential damage caused by malfunctions in it. For the purposes of this book, some of the impacts of reliability harm will be integrated into the discussion of the functionality of software. Raymond makes the case that this harm varies as a function of the complexity of the software because more complex software is more likely to contain bugs and with the expected consequences of bugs. For the average user, the greatest potential negative consequences often come from various security threats found on the Internet, such as viruses and spyware. Thus, the extent to which the software exposes the user to the internet shall be a primary factor in determining reliability harm.

However, it does not follow from the idea that open source development is better at finding and fixing bugs in software that all open source projects must have fewer bugs than all closed source proprietary programs nor does it necessarily mean that any of the bugs in the code have a large impact on the user experience. Therefore, reliability comparisons are best done directly between the software in question when possible. 

Furthermore, the benefits of open source development in terms of improving the reliability of software are not entirely dependent upon the software license like many of the other benefits that will be discussed. Though it is not possible to entirely replicate the benefits of open source development with a proprietary license because of the lack of possiblity of anyone to run their own modified versions or fork the software, some of them can certainly be done either by releasing source code to some other developers via a restrictive license[85] or for a sufficiently large company by replicated open source practices internally.

Reliability is also something that is very easy wrapped up in the question of functionality and already  

Unhackability harm is the harm that comes from the inability of the users to modify the software in order to customize it to their specific needs. Considering that most of the people who benefit from this aspect of software licensing are either programmers with the ability to modify the software themselves or commercial software consumers with the money and need to pay programmers to do it for them. For the average software consumer, such harm is likely to only manifest itself in the form of missing features that are included in our already present functionality analysis. To a lesser extend, unhackability harm could materialize in lost potential future functionality. Perhaps features will be developed for open source software that are not commercially viable for a proprietary developer to add to existing software.

Agency harm is a large enough topic that it merits an entire chapter of its own. Raymond defines it as the ability of software developers to use their asymmetric relationship with their users to restrict choices, control their users' data and extract rents. Raymond discusses these harms only in terms of the ability of developers to do these things, but the person or company that is given these powers also plays an incredibly important role. 

For the most knowledgeable computer users, decisions can be made on the basis of whether or not such powers are actually being exercised at the moment. But, how many of any given browser's millions of users would know if support for certain video codecs were dropped or added or if changes were made in what data was being sent to the developers of the browser? How many of those would switch away from using their otherwise favorite browser as a result compared to the number that would just mindlessly update their software to the latest version regardless of the changes the developer has made? If Internet Explorer's fading dominance of the browser market has taught us anything, it's that the answer is far too few. Thus for the average user, the importance of the historical record of the developer is significantly more important.

Raymond describes the root of agency harm as deriving from the ability of closed source developers to be "privileged to see inside [software] and modify it." Though it is not quite clear from his initial description, when he discusses agency harm applied to specific software areas it becomes clear he is only referring to the harm that can come from the specific software program in question and not any less direct implications that come from the relationship between a software developer and a user.

There are also other kinds of indirect harm that are very closely related to what Raymond called agency harm because they too derive from the asymmetric relationship between a software developer and users. For example, even though a software developer produces software that allows users complete freedom, it is possible for them to leverage the power of user base to place restrictions on users or extract rents from them in other ways. This indirect agency harm is especially powerful when it comes to establishing standards in a software market with many players. A second way that software use contributes to agency harm is in providing revenue that a company or individual can spend on whatever other software projects they wish.

To distinguish between the kinds of agency harm that Raymond was talking about and my own kinds, I will refer to Raymond's agency harm as direct agency harm, which will include only harms that come directly from the software in question, and call the kinds of harm I have just described indirect agency harm. To help make the distinction clear, take the example of a basic Google search. Google's data collection and the potential for privacy violations as a result constitute direct agency harm. It comes as a result of the code that users run in their browsers and cause to run on Google's servers. The potential for indirect agency harm occurs because searches generate revenue for Google through ads. This revenue is money that Google can use to fund software development projects of any kind.

A final important distinction between direct and indirect agency harm is that direct agency harm can only ever be negative. Since software is supposed to be beneficial and it can reasonably be assumed the the direct benefits of using software are known by the user, it is only possible for restrictions, data control and extracted rents to be negative. The assumption is that users should face no imposed restrictions or inability to control their data and that any code designed not to allow for such freedom is a harm. In the case of indirect agency harm, it is possible for it to either be a positive or a negative. A software developer could go out of their way to leverage their user base to achieve good by pushing for open standards on the web, they could choose to do nothing with their profits and perhaps just pass them onto shareholders, or they could do harm by exerting their market power to further lock-in and restrict users in new ways.

Lock-in harm is the difficulty of switching away from software. In this case, the important license is not usually that of the software, but of the format in which is stores data. The most obvious example is that of productivity suites. Microsoft Office uses proprietary formats such as .docx, .xlsx and .pptx as default save formats. No other software can properly read data saved in these formats creating a tremendous cost of switching to another set of productivity software. Lock-in harm can first be evaluated on a threshold basis, either the data is locked up in a restricted format or it is not. In the case of locked-in data, the harm is directly proportional to the cost of changing it to a different format.

Amnesia harm is the cost that comes when a proprietary software or format is abandoned and the capabilities and knowledge that it utilized or are stored in it are lost. Such harm increases with the complexity and uniqueness of the software in question or the value of data stored in such a format and the likelihood that the ability to access it will be lost which should be inversely proportional to the number of people with access to the knowledge. Thus the most high risk scenario is one where valuable data is being saved in a complex and unique format developed by a small number of people.

The final type of harm that Raymond mentions is positive network effects. Network effects in the software market will be discussed in detail in a later chapter. On the most basic level, network effects are when the value of a product is increased by the number of users. Social networks like Facebook and Twitter are the obvious examples. Raymond compares the harm from network effects to that of lock-in harm in that they raise the cost of transitioning away. However, the impact of them is much greater than just that. When network effects are present they act as a multiplier on all the other types of harm because irrespective of those kinds of harm in one direction or the other because they encourage people to use software. Calling positive network effects exclusively a harm is also not correct because while they can raise the costs of moving away from software, they can also encourage its adoption. Network effects also have no dependence on the software license in question and only on the number of users, thus my analysis will treat them not as a harm that stems from restrictive software licenses, but rather as a multiplier effect that magnifies either the harms or benefits of a given software choice. It is also possible for network effects to be considered a measure of difficulty in opening restrictive software monopolies when it comes to things like ending proprietary format monopolies.

In addition the harms discussed by Raymond, our analysis requires the additional discussion of the harms from restrictive open source licenses. This comes when a software developer chooses to write their own software rather than using software that already exists because of the license. I will refer to this harm as reinventing the wheel harm because it is essentially the harm caused by programmers choosing or being forced to write new code to do something that someone has already written software to do.

The variables that contribute to reinventing the wheel harm are difficult to quantify because they depend so much on the preferences of the developer in question, which itself is sometimes and unknown. The most simplistic way to treat it would be to treat it as an increasing function of software restrictiveness. But some developers may shy away from using software with certain restrictions, but not others, so such a model is clearly wrong and whether or not it is useful is a purely empirical question. A much better model to deal with with quantifying reinventing the wheel harm is to deal with groups of developers that have similar preferences for software licenses. Such a model will be pursued in the following chapter that makes the case for using the most libertarian license possible.

____________

[79] Eric S. Raymond, "Incentives to be Open", April 19 2010, accessed July 1, 2012, online at http://esr.ibiblio.org/?p=1917 
[80] Alexis de Tocqueville Institution, "Opening the Open Source Debate: A White Paper", June 2002, the original paper can no longer be found online as the Alexis de Tocqueville Institution is no longer operating. The quote is sourced through A. Boulanger, "Open-source versus proprietary software: Is one more reliable and secure than the other?", IBM Systems Journal, Vol. 44, No. 2, 2005, pg. 247, online at http://www.cs.bris.ac.uk/Teaching/learning/how-to-lectures/boulanger.pdf
[81] A. Boulanger, "Open-source versus proprietary software: Is one more reliable and secure than the other?", IBM Systems Journal, Vol. 44, No. 2, 2005, pg. 247, online at http://www.cs.bris.ac.uk/Teaching/learning/how-to-lectures/boulanger.pdf
[82] Reasoning, "How Open-Source and Commercial Software Compare: A Quantitative Analysis of TCP/IP Implementations in Commercial Software and in the Linux Kernel", 2003, online at http://www.reasoning.com/pdf/Open_Source_White_Paper_v1.1.pdf
[83] Reasoning, "How Open-Source and Commercial Software Compare: Database Implementation in Commercial Software and in MySQL", 2003, online athttp://www.reasoning.com/pdf/MySQL_White_Paper.pdf
[84] Ibid.
[85] Microsoft has attempted to do just this via a group of licenses of varying levels of restriction in a program called their Shared Source Initiative. More information is available online at http://www.microsoft.com/en-us/sharedsource/default.aspx.
